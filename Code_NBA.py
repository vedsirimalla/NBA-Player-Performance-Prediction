# -*- coding: utf-8 -*-
"""NBA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CjrvIulQBN9tKrIm4vCbt7aEjLltf4yz
"""

!pip install kaggle

!mkdir -p ~/.kaggle

!kaggle datasets download -d bryanchungweather/nba-player-stats-dataset-for-the-2023-2024

!unzip nba-player-stats-dataset-for-the-2023-2024.zip

"""# Data Manipulation

### Load and combine the data:
"""

import pandas as pd
import os

# List all CSV files in the current directory
csv_files = [file for file in os.listdir() if file.endswith('.csv') and 'NBA_2024_per_game' in file]

# Read and combine all CSV files
df_list = [pd.read_csv(file) for file in csv_files]
df = pd.concat(df_list, ignore_index=True)
print(f"Original dataset shape: {df.shape}")

# Check the total number of rows before removing duplicates
print(f"Total rows before removing duplicates: {len(df)}")

# Check the number of duplicate rows
duplicate_count = df.duplicated().sum()
print(f"Number of duplicate rows: {duplicate_count}")

# Remove duplicate rows based on all columns
df = df.drop_duplicates()

# Check the total number of rows after removing duplicates
print(f"Total rows after removing duplicates: {len(df)}")

print(f"Combined dataset shape: {df.shape}")

"""The presence of duplicates could be due to:
1. Multiple updates of the same games in different CSV files
2. Players appearing multiple times if they changed teams during the season

### Handling missing values
"""

# Check for missing values
print(df.isnull().sum())

# Fill missing values with appropriate methods
df['FG%'] = df['FG%'].fillna(df['FG%'].mean())
df['3P%'] = df['3P%'].fillna(df['3P%'].mean())
df['2P%'] = df['2P%'].fillna(df['2P%'].mean())
df['eFG%'] = df['eFG%'].fillna(df['eFG%'].mean())
df['FT%'] = df['FT%'].fillna(df['FT%'].mean())

# Drop rows with missing values in other columns
df.dropna(inplace=True)

# After the dropna() operation
print("Columns and their data types after data cleaning:")
print(df.dtypes)

print("\nNumber of rows and columns:")
print(df.shape)

print("\nFirst few rows of the cleaned dataset:")
print(df.head())

print("\nSummary statistics of numerical columns:")
print(df.describe())

# Check for missing values again
print(df.isnull().sum())

"""### Convert data types:"""

# Convert percentage columns to float
percentage_cols = ['FG%', '3P%', '2P%', 'eFG%', 'FT%']
for col in percentage_cols:
    df[col] = df[col].astype(str).str.rstrip('%').astype('float') / 100.0

# Convert 'Age' to integer type
df['Age'] = df['Age'].astype(int)

"""### Create new features:.

"""

# Create a new feature 'PointsPerMinute'
df['PointsPerMinute'] = df['PTS'] / df['MP']

# Create a new feature 'TotalRebounds'
df['TotalRebounds'] = df['ORB'] + df['DRB']

# Create a new feature 'ShootingEfficiency'
df['ShootingEfficiency'] = (df['FG%'] + df['3P%'] + df['FT%']) / 3

"""### Filter and categorize data:

1. It creates an explicit copy of the filtered DataFrame using .copy(). This ensures that df_filtered is a new DataFrame and not a view of the original df.
2. It uses the .loc accessor to assign the new 'ScoringCategory' column. This is the recommended way to add or modify columns in pandas to avoid warnings and ensure that the operation works as intended.
"""

# Filter players who played more than 10 games
df_filtered = df[df['G'] > 10].copy()  # Create an explicit copy

# Categorize players based on their scoring average
def scoring_category(pts):
    if pts < 10:
        return 'Low Scorer'
    elif pts < 20:
        return 'Average Scorer'
    else:
        return 'High Scorer'

# Use .loc to assign the new column
df_filtered.loc[:, 'ScoringCategory'] = df_filtered['PTS'].apply(scoring_category)

print(df_filtered.dtypes)
print(df_filtered.shape)
print(df_filtered.head())
print(df_filtered.describe())

"""### Handle outliers:

Purpose:
* Outliers can significantly skew statistical analyses and machine learning models.
* Removing them can lead to more robust and accurate results.

Method Explanation:
*Â The IQR is the range between the first quartile (25th percentile) and third quartile (75th percentile).
* Values below Q1 - 1.5IQR or above Q3 + 1.5IQR are considered outliers.
* This method is less sensitive to extreme values compared to using standard deviations.
"""

import numpy as np

# Function to remove outliers using IQR method
def remove_outliers(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]

# Remove outliers from key statistics
for col in ['PTS', 'TRB', 'AST', 'STL', 'BLK']:
    df_filtered = remove_outliers(df_filtered, col)

print(f"Dataset shape after outlier removal: {df_filtered.shape}")

"""### Normalize numerical features:

The purpose of this normalization is to:
* Bring all features to a similar scale, which is important for many machine learning algorithms.
* Ensure that features with larger values don't dominate the learning process.
* Improve the convergence of gradient descent algorithms.

StandardScaler specifically:
* Calculates the mean and standard deviation of each feature.
* Subtracts the mean from each data point (centering the data).
* Divides by the standard deviation (scaling to unit variance).


After this step, each normalized feature will have a mean of 0 and a standard deviation of 1. This is particularly useful for algorithms that assume the data is normally distributed or for comparing features that originally had different scales.
"""

from sklearn.preprocessing import StandardScaler

# Select numerical columns for normalization
numerical_cols = ['Age', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS']

# Initialize the StandardScaler
scaler = StandardScaler()

# Fit the scaler to the data and transform
df_normalized = df_filtered.copy()
df_normalized[numerical_cols] = scaler.fit_transform(df_filtered[numerical_cols])

print("Data normalized using StandardScaler")
print(df_normalized.shape)

"""### Save the processed dataset:"""

# Save the processed dataset to a new CSV file
df_filtered.to_csv('nba_2024_processed.csv', index=False)
print("Processed dataset saved to 'nba_2024_processed.csv'")

"""# EDA


This comprehensive analysis provides several key points for your presentation:

1. Team Distribution: Visualize how players are distributed across teams, highlighting any imbalances.

2. Age vs Performance: Explore the relationship between a player's age and their scoring output, identifying peak performance age ranges.
3. Position Analysis: Compare average statistics across different positions, showcasing the unique contributions of each role.
4. Efficiency Analysis: Examine the relationship between scoring efficiency (True Shooting Percentage) and points scored.
5. Correlation Analysis: Highlight relationships between key statistics, potentially revealing interesting patterns or trade-offs in player performance.
6. Top Performers: Identify standout players in various statistical categories, providing concrete examples of exceptional performance.
7. Playing Time vs Production: Visualize the relationship between minutes played and points scored, including a trend line to show the general pattern.
8. Statistical Tests: Perform correlation and ANOVA tests to statistically validate observations about the relationships between variables.

These analyses will help us understand:
How the dataset is spread across teams, positions, and age groups
Key relationships between different performance metrics
Standout players and performances
General trends and patterns in NBA player statistics

During your presentation, we can use these insights to discuss:
The distribution of talent across the league
How age and position affect player performance
The relationship between playing time and production
Efficiency metrics and their importance
Statistical evidence for observed trends in the data

### Check column names
"""

print(df_filtered.columns)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from scipy import stats

# Assuming df_filtered is your preprocessed DataFrame

# 1. Player Distribution Analysis
plt.figure(figsize=(12, 6))
team_counts = df_filtered['Tm'].value_counts()
sns.barplot(x=team_counts.index, y=team_counts.values)
plt.title('Number of Players per Team')
plt.xticks(rotation=90)
plt.ylabel('Number of Players')
plt.show()

print(f"Total number of players: {len(df_filtered)}")
print(f"Number of teams: {df_filtered['Tm'].nunique()}")

# 2. Age vs Performance Analysis
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Age', y='PTS', data=df_filtered, alpha=0.6)
plt.title('Age vs Points per Game')
plt.show()

age_groups = pd.cut(df_filtered['Age'], bins=[0, 22, 26, 30, 35, 100], labels=['<22', '22-25', '26-30', '31-35', '>35'])
avg_points = df_filtered.groupby(age_groups)['PTS'].mean().round(2)
print("Average points per game by age group:")
print(avg_points)

# 3. Position Analysis
pos_stats = df_filtered.groupby('Pos')[['PTS', 'TRB', 'AST']].mean().round(2)
print("\nAverage stats by position:")
print(pos_stats)

plt.figure(figsize=(12, 6))
sns.boxplot(x='Pos', y='G', data=df_filtered)
plt.title('Games Played Distribution by Position')
plt.show()

# 4. Efficiency Analysis
df_filtered['TS%'] = df_filtered['PTS'] / (2 * (df_filtered['FGA'] + 0.44 * df_filtered['FTA'])) # True Shooting Percentage
plt.figure(figsize=(10, 6))
sns.scatterplot(x='TS%', y='PTS', data=df_filtered, alpha=0.6)
plt.title('True Shooting Percentage vs Points per Game')
plt.xlabel('True Shooting Percentage (TS%)')
plt.ylabel('Points per Game')
plt.show()

# 5. Correlation Analysis
corr_matrix = df_filtered[['PTS', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF']].corr()
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap of Key Statistics')
plt.show()

# 6. Top Performers in Different Categories
categories = ['PTS', 'TRB', 'AST', 'STL', 'BLK']
for category in categories:
    top_5 = df_filtered.nlargest(5, category)[['Player', 'Tm', category]]
    print(f"\nTop 5 players in {category}:")
    print(top_5)

# 7. Playing Time vs Production
plt.figure(figsize=(12, 8))
plt.scatter(df_filtered['MP'], df_filtered['PTS'], alpha=0.6)
plt.xlabel('Minutes Played per Game')
plt.ylabel('Points per Game')
plt.title('Minutes Played vs Points Scored')
z = np.polyfit(df_filtered['MP'], df_filtered['PTS'], 1)
p = np.poly1d(z)
plt.plot(df_filtered['MP'], p(df_filtered['MP']), "r--")
plt.show()

# 8. Statistical Tests
print("\nCorrelation between Minutes Played and Points:")
correlation, p_value_corr = stats.pearsonr(df_filtered['MP'], df_filtered['PTS'])
print(f"Pearson correlation: {correlation:.2f}, p-value: {p_value_corr:.3f}")

print("\nANOVA test for Points across Positions:")
positions = df_filtered['Pos'].unique()
point_groups = [df_filtered[df_filtered['Pos'] == pos]['PTS'] for pos in positions]
f_value, p_value_anova = stats.f_oneway(*point_groups)
print(f"F-value: {f_value:.2f}, p-value: {p_value_anova:.3f}")

"""# Goal

##### Develop a deep learning model to predict NBA player performance, specifically Points Per Game (PPG).

##### Using both an LSTM (Long Short-Term Memory) model and an MLP (Multi-Layer Perceptron) model for comparison.

### Data Preparation
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Select features and target
features = ['MP', 'FG%', '3P%', 'FT%', 'TRB', 'AST', 'STL', 'BLK']
target = 'PTS'

X = df_filtered[features].values
y = df_filtered[target].values

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""# LSTM Model"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

# Reshape input for LSTM (samples, time steps, features)
X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))
X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))

# LSTM Model Definition
def create_lstm_model(input_shape):
    model = Sequential([
        LSTM(64, return_sequences=True, input_shape=input_shape),
        LSTM(32),
        Dense(16, activation='relu'),
        Dense(1)
    ])
    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])
    return model

# Create and train the LSTM model
lstm_model = create_lstm_model((1, X_train.shape[1]))
early_stopping = EarlyStopping(patience=10, restore_best_weights=True)
lstm_history = lstm_model.fit(X_train_lstm, y_train, epochs=100, batch_size=32,
                              validation_split=0.2, callbacks=[early_stopping], verbose=1)

# Evaluate LSTM model
lstm_mae = lstm_model.evaluate(X_test_lstm, y_test)[1]
print(f"LSTM MAE: {lstm_mae:.2f}")

# Generate predictions
lstm_predictions = lstm_model.predict(X_test_lstm).flatten()

"""# MLP Model"""

from tensorflow.keras.layers import Dense, Dropout

# MLP Model Definition
def create_mlp_model(input_shape):
    model = Sequential([
        Dense(64, activation='relu', input_shape=(input_shape,)),
        Dropout(0.2),
        Dense(32, activation='relu'),
        Dropout(0.2),
        Dense(16, activation='relu'),
        Dense(1)
    ])
    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])
    return model

# Create and train the MLP model
mlp_model = create_mlp_model(X_train.shape[1])
mlp_history = mlp_model.fit(X_train_scaled, y_train, epochs=100, batch_size=32,
                            validation_split=0.2, verbose=1)

# Evaluate MLP model
mlp_mae = mlp_model.evaluate(X_test_scaled, y_test)[1]
print(f"MLP MAE: {mlp_mae:.2f}")

# Generate predictions
mlp_predictions = mlp_model.predict(X_test_scaled).flatten()

"""# Visualization and Comparison"""

# Visualize predictions
plt.figure(figsize=(12, 6))
plt.scatter(y_test, lstm_predictions, label='LSTM', alpha=0.5)
plt.scatter(y_test, mlp_predictions, label='MLP', alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel('Actual Points per Game')
plt.ylabel('Predicted Points per Game')
plt.title('LSTM vs MLP: Actual vs Predicted Points per Game')
plt.legend()
plt.show()

# Plot training history
plt.figure(figsize=(12, 6))
plt.plot(lstm_history.history['loss'], label='LSTM Training Loss')
plt.plot(lstm_history.history['val_loss'], label='LSTM Validation Loss')
plt.plot(mlp_history.history['loss'], label='MLP Training Loss')
plt.plot(mlp_history.history['val_loss'], label='MLP Validation Loss')
plt.title('Model Loss During Training')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""# Data Preparation
- **Feature Selection**:
  - Selected features based on basketball knowledge and insights from Exploratory Data Analysis (EDA).
- **Data Splitting and Scaling**:
  - Highlighted the importance of splitting the dataset into training, validation, and testing subsets.
  - Used scaling techniques to optimize data for deep learning models.

# LSTM Model
- **Overview**:
  - Explained why Long Short-Term Memory (LSTM) networks are suitable for sequential data, capturing game-to-game performance changes.
- **Architecture**:
  - Defined input shape and discussed the arrangement of LSTM layers and dense layers.
  - Utilized the Adam optimizer for adaptive learning and Mean Squared Error (MSE) as the loss function.

# MLP Model
- **Overview**:
  - Discussed how Multi-Layer Perceptron (MLP) models capture non-linear relationships between features.
- **Architecture**:
  - Detailed dense layers with dropout for regularization.
  - Compared the simplicity of MLP to the complexity of LSTM.

# Model Training
- **Early Stopping**:
  - Explained its role in preventing overfitting by monitoring validation loss.
- **Loss and Validation Loss**:
  - Discussed their significance in evaluating model performance during training.

# Model Evaluation
- **Mean Absolute Error (MAE)**:
  - Interpreted MAE results for both models.
- **Performance Comparison**:
  - Compared LSTM and MLP in terms of predictive accuracy and computational complexity.

# Visualizations
- **Scatter Plot**:
  - Explained the scatter plot showing actual vs. predicted points, emphasizing prediction accuracy.
- **Training History Plot**:
  - Discussed how the models learned over epochs, focusing on loss and validation loss trends.

# Conclusions
- **Summary**:
  - Summarized which model performed better and the underlying reasons for its success.
- **Future Improvements**:
  - Suggested enhancements and potential directions for further research and development.

# More Deep Learning Models

## Convolutional Neural Network (CNN)
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense

def create_cnn_model(input_shape):
    model = Sequential([
        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),
        MaxPooling1D(pool_size=2),
        Flatten(),
        Dense(50, activation='relu'),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
    return model

# Reshape input data for CNN
X_train_cnn = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))
X_test_cnn = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))

cnn_model = create_cnn_model((X_train_cnn.shape[1], 1))
cnn_history = cnn_model.fit(X_train_cnn, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)

"""## Bidirectional LSTM"""

from tensorflow.keras.layers import Bidirectional, LSTM

def create_bidirectional_lstm_model(input_shape):
    model = Sequential([
        Bidirectional(LSTM(64, return_sequences=True), input_shape=input_shape),
        Bidirectional(LSTM(32)),
        Dense(16, activation='relu'),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
    return model

bilstm_model = create_bidirectional_lstm_model((X_train_lstm.shape[1], X_train_lstm.shape[2]))
bilstm_history = bilstm_model.fit(X_train_lstm, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)

"""## Gated Recurrent Unit (GRU)"""

from tensorflow.keras.layers import GRU

def create_gru_model(input_shape):
    model = Sequential([
        GRU(64, return_sequences=True, input_shape=input_shape),
        GRU(32),
        Dense(16, activation='relu'),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
    return model

gru_model = create_gru_model((X_train_lstm.shape[1], X_train_lstm.shape[2]))
gru_history = gru_model.fit(X_train_lstm, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)

"""## Transformer"""

from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dropout, Input, GlobalAveragePooling1D
from tensorflow.keras.models import Model

def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):
    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)
    x = Dropout(dropout)(x)
    x = LayerNormalization(epsilon=1e-6)(x)
    res = x + inputs
    x = Dense(ff_dim, activation="relu")(res)
    x = Dropout(dropout)(x)
    x = Dense(inputs.shape[-1])(x)
    return LayerNormalization(epsilon=1e-6)(x + res)

def create_transformer_model(input_shape):
    inputs = Input(shape=input_shape)
    x = transformer_encoder(inputs, head_size=256, num_heads=4, ff_dim=4, dropout=0.1)
    x = GlobalAveragePooling1D(data_format="channels_first")(x)
    outputs = Dense(1)(x)
    return Model(inputs, outputs)

transformer_model = create_transformer_model((X_train_lstm.shape[1], X_train_lstm.shape[2]))
transformer_model.compile(optimizer='adam', loss='mse', metrics=['mae'])
transformer_history = transformer_model.fit(X_train_lstm, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)

"""# Visualization and Comparison"""

import matplotlib.pyplot as plt

# Visualize predictions

plt.figure(figsize=(20, 12))
models = ['LSTM', 'MLP', 'CNN', 'BiLSTM', 'GRU', 'Transformer']
predictions = [lstm_predictions, mlp_predictions, cnn_predictions,
               bilstm_predictions, gru_predictions, transformer_predictions]

for i, (model, pred) in enumerate(zip(models, predictions)):
    plt.subplot(2, 3, i+1)
    plt.scatter(y_test, pred, alpha=0.5, label=model)
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
    plt.xlabel('Actual Points per Game')
    plt.ylabel('Predicted Points per Game')
    plt.title(f'{model}: Actual vs Predicted Points per Game')
    plt.legend()

plt.tight_layout()
plt.show()

# Plot training history
plt.figure(figsize=(20, 12))
histories = [lstm_history, mlp_history, cnn_history,
             bilstm_history, gru_history, transformer_history]

for i, (model, history) in enumerate(zip(models, histories)):
    plt.subplot(2, 3, i+1)
    plt.plot(history.history['loss'], label=f'{model} Training Loss')
    plt.plot(history.history['val_loss'], label=f'{model} Validation Loss')
    plt.title(f'{model} Loss During Training')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

plt.tight_layout()
plt.show()

"""# Generate Predictions for all models"""

lstm_predictions = lstm_model.predict(X_test_lstm).flatten()
mlp_predictions = mlp_model.predict(X_test_scaled).flatten()
cnn_predictions = cnn_model.predict(X_test_cnn).flatten()
bilstm_predictions = bilstm_model.predict(X_test_lstm).flatten()
gru_predictions = gru_model.predict(X_test_lstm).flatten()
transformer_predictions = transformer_model.predict(X_test_lstm).flatten()

"""# Evaluate all models:"""

models = [lstm_model, mlp_model, cnn_model, bilstm_model, gru_model, transformer_model]
model_names = ['LSTM', 'MLP', 'CNN', 'BiLSTM', 'GRU', 'Transformer']
test_data = [X_test_lstm, X_test_scaled, X_test_cnn, X_test_lstm, X_test_lstm, X_test_lstm]

for model, name, data in zip(models, model_names, test_data):
    mae = model.evaluate(data, y_test)[1]
    print(f"{name} MAE: {mae:.2f}")

"""# Visualize predictions:"""

import matplotlib.pyplot as plt

plt.figure(figsize=(20, 12))
predictions = [lstm_predictions, mlp_predictions, cnn_predictions, bilstm_predictions, gru_predictions, transformer_predictions]

for i, (name, pred) in enumerate(zip(model_names, predictions)):
    plt.subplot(2, 3, i+1)
    plt.scatter(y_test, pred, alpha=0.5)
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
    plt.xlabel('Actual PPG')
    plt.ylabel('Predicted PPG')
    plt.title(f'{name} Predictions')

plt.tight_layout()
plt.show()

"""# Compare model performance:"""

from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

results = []
for name, pred in zip(model_names, predictions):
    mse = mean_squared_error(y_test, pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, pred)
    results.append([name, mse, rmse, r2])

results_df = pd.DataFrame(results, columns=['Model', 'MSE', 'RMSE', 'R2'])
print(results_df)

"""# Analyze feature importance (for MLP model):

The purpose of analyzing feature importance for MLP models is to understand which input variables have the most significant impact on the model's predictions.
"""

import shap

explainer = shap.Explainer(mlp_model.predict, X_train_scaled)
shap_values = explainer(X_test_scaled)

shap.summary_plot(shap_values, X_test_scaled, feature_names=features)

# Plot the summary of SHAP values
shap.summary_plot(shap_values, X_test_scaled)

"""# Make predictions for new players:

This code does the following:
1. Defines a predict_ppg function that can handle the input requirements of all 6 models.
2. Selects a random player from the test set.
3. Predicts the PPG for this player using all 6 models.
4. Prints the actual PPG alongside the predictions from each model.

This approach allows us to compare how well each model predicts PPG for a real player in your dataset, rather than using arbitrary example stats. It provides a more realistic assessment of each model's performance on unseen data.
"""

import numpy as np

def predict_ppg(model, player_stats, scaler):
    scaled_stats = scaler.transform(player_stats.reshape(1, -1))
    if model in [lstm_model, bilstm_model, gru_model, transformer_model]:
        scaled_stats = scaled_stats.reshape((1, 1, scaled_stats.shape[1]))
    elif model == cnn_model:
        scaled_stats = scaled_stats.reshape((1, scaled_stats.shape[1], 1))
    return model.predict(scaled_stats)[0][0]

# Ensure features is a list or numpy array
features = list(features)

# Select a random player from the test set
random_index = np.random.randint(0, len(X_test))
test_player = X_test[random_index]
actual_ppg = y_test[random_index]

# Get player name (assuming you have a DataFrame with player names)
player_name = df_filtered['Player'].iloc[random_index]

models = [lstm_model, mlp_model, cnn_model, bilstm_model, gru_model, transformer_model]
model_names = ['LSTM', 'MLP', 'CNN', 'BiLSTM', 'GRU', 'Transformer']

print(f"Selected player: {player_name}")
print(f"Actual PPG: {actual_ppg:.2f}")

for model, name in zip(models, model_names):
    try:
        ppg_prediction = predict_ppg(model, test_player, scaler)
        print(f"{name} predicts {ppg_prediction:.2f} PPG")
    except Exception as e:
        print(f"Error predicting with {name}: {str(e)}")

"""Based on the final results for predicting Dante Exum's Points Per Game (PPG), we can draw the following closing thoughts:

1. Model Performance: All six deep learning models (LSTM, MLP, CNN, BiLSTM, GRU, and Transformer) performed reasonably well in predicting Dante Exum's PPG. The predictions ranged from 3.47 to 4.38 PPG, compared to the actual 4.40 PPG.
2. Best Performing Model: The Bidirectional LSTM (BiLSTM) model showed the most accurate prediction, with 4.38 PPG, which is remarkably close to the actual value of 4.40 PPG.
3. Consistency: Most models (LSTM, MLP, CNN, BiLSTM, and GRU) provided predictions within a narrow range of 3.99 to 4.38 PPG, suggesting a good level of consistency across different architectures.
4. Outlier: The Transformer model's prediction of 3.47 PPG was the least accurate, underestimating Exum's performance by nearly a full point. This suggests that the Transformer architecture might need further tuning for this specific prediction task.
5. Practical Implications: The ability to predict a player's PPG within such a close range demonstrates the potential of these models for player performance analysis, scouting, and strategic decision-making in professional basketball.
6. Future Improvements: While the predictions are generally good, there's still room for improvement. Fine-tuning hyperparameters, incorporating more relevant features, or exploring ensemble methods could potentially enhance prediction accuracy.
7. Model Selection: For future predictions, the BiLSTM model appears to be the most promising, but it would be advisable to test these models on a larger set of players to confirm their overall effectiveness and consistency.

These results highlight the power of deep learning in sports analytics and showcase the potential for accurate player performance prediction in the NBA.

# Final Goal:

The goal of this project is to predict NBA player performance, specifically Points Per Game (PPG), using six different deep learning models. The models being used are:

1. LSTM (Long Short-Term Memory)
2. MLP (Multi-Layer Perceptron)
3. CNN (Convolutional Neural Network)
4. BiLSTM (Bidirectional LSTM)
5. GRU (Gated Recurrent Unit)
6. Transformer

These models are being trained and evaluated to forecast a player's scoring output.
"""